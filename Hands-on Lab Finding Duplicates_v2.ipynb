{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Duplicates Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling is a critical step in preparing datasets for analysis, and handling duplicates plays a key role in ensuring data accuracy. In this lab, you will focus on identifying and removing duplicate entries from your dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify duplicate rows in the dataset and analyze their characteristics.\n",
    "2. Visualize the distribution of duplicates based on key attributes.\n",
    "3. Remove duplicate values strategically based on specific criteria.\n",
    "4. Outline the process of verifying and documenting duplicate removal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the needed library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m144.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m148.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.1 pandas-2.3.1 tzdata-2025.2\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (107 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m129.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m156.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.3.0 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the dataset into a dataframe**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read Data</h2>\n",
    "<p>\n",
    "We utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset directly from the URL\n",
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VYPrOu0Vs3I0hKLLjiPGrA/survey-data-with-duplicate.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into a pandas dataframe:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you are working on a local Jupyter environment, you can use the URL directly in the pandas.read_csv() function as shown below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and Analyze Duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Identify Duplicate Rows\n",
    "1. Count the number of duplicate rows in the dataset.\n",
    "3. Display the first few duplicate rows to understand their structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "num_duplicate_rows = df.duplicated().sum()\n",
    "if num_duplicate_rows > 0:\n",
    "        print(\"--- First few duplicate rows (keeping all occurrences) ---\")\n",
    "        # df.duplicated(keep=False) marks all occurrences of a duplicate row as True\n",
    "        duplicate_rows = df[df.duplicated(keep=False)]\n",
    "        print(duplicate_rows.head())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Analyze Characteristics of Duplicates\n",
    "1. Identify duplicate rows based on selected columns such as MainBranch, Employment, and RemoteWork. Analyse which columns frequently contain identical values within these duplicate rows.\n",
    "2. Analyse the characteristics of rows that are duplicates based on a subset of columns, such as MainBranch, Employment, and RemoteWork. Determine which columns frequently have identical values across these rows.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows based on 'MainBranch, Employment, RemoteWork': 64876\n",
      "-------------------------------------\n",
      "\n",
      "--- First few duplicate rows based on 'MainBranch, Employment, RemoteWork' (keeping all occurrences) ---\n",
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "-----------------------------------------------------------\n",
      "\n",
      "--- Analysis of identical values in duplicate rows for 'MainBranch, Employment, RemoteWork' ---\n",
      "\n",
      "Frequency of values in 'MainBranch' within duplicate rows:\n",
      "MainBranch\n",
      "I am a developer by profession                                                           50161\n",
      "I am not primarily a developer, but I write code sometimes as part of my work/studies     6468\n",
      "I am learning to code                                                                     3845\n",
      "I code primarily as a hobby                                                               3314\n",
      "I used to be a developer by profession, but no longer am                                  1482\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Frequency of values in 'Employment' within duplicate rows:\n",
      "Employment\n",
      "Employed, full-time                                                                                                                                                       39038\n",
      "Independent contractor, freelancer, or self-employed                                                                                                                       4844\n",
      "Student, full-time                                                                                                                                                         4709\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed                                                                                                   3557\n",
      "Not employed, but looking for work                                                                                                                                         2341\n",
      "                                                                                                                                                                          ...  \n",
      "Employed, full-time;Student, full-time;Student, part-time                                                                                                                     2\n",
      "Independent contractor, freelancer, or self-employed;Student, part-time;Retired                                                                                               2\n",
      "Not employed, but looking for work;Retired                                                                                                                                    2\n",
      "Not employed, and not looking for work;Employed, part-time                                                                                                                    2\n",
      "Employed, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time        2\n",
      "Name: count, Length: 72, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Frequency of values in 'RemoteWork' within duplicate rows:\n",
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    22974\n",
      "Remote                                  20779\n",
      "In-person                               10923\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "columns_for_duplicate_check = ['MainBranch', 'Employment', 'RemoteWork']\n",
    "\n",
    "    # Count the number of duplicate rows based on the specified subset of columns\n",
    "    # df.duplicated(subset=columns_for_duplicate_check).sum() counts rows where the subset is duplicated\n",
    "num_duplicate_rows_subset = df.duplicated(subset=columns_for_duplicate_check).sum()\n",
    "print(f\"Number of duplicate rows based on '{', '.join(columns_for_duplicate_check)}': {num_duplicate_rows_subset}\")\n",
    "print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # Display the first few duplicate rows based on the subset\n",
    "if num_duplicate_rows_subset > 0:\n",
    "    print(f\"--- First few duplicate rows based on '{', '.join(columns_for_duplicate_check)}' (keeping all occurrences) ---\")\n",
    "        # df.duplicated(subset=columns_for_duplicate_check, keep=False) marks all occurrences as True\n",
    "    duplicate_rows_subset = df[df.duplicated(subset=columns_for_duplicate_check, keep=False)]\n",
    "    print(duplicate_rows_subset.head())\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "        # Analyze which columns frequently contain identical values within these duplicate rows\n",
    "    print(f\"--- Analysis of identical values in duplicate rows for '{', '.join(columns_for_duplicate_check)}' ---\")\n",
    "    for col in columns_for_duplicate_check:\n",
    "        if col in duplicate_rows_subset.columns:\n",
    "            print(f\"\\nFrequency of values in '{col}' within duplicate rows:\")\n",
    "            print(duplicate_rows_subset[col].value_counts())\n",
    "            print(\"-\" * 30)\n",
    "        else:\n",
    "            print(f\"Column '{col}' not found in the duplicate rows DataFrame.\")\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "else:\n",
    "    print(f\"No duplicate rows found based on '{', '.join(columns_for_duplicate_check)}' to display or analyze.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Visualize Duplicates Distribution\n",
    "1. Create visualizations to show the distribution of duplicates across different categories.\n",
    "2. Use bar charts or pie charts to represent the distribution of duplicates by Country and Employment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read data from: survey_data.csv\n",
      "Successfully loaded 'survey_data.csv' into a DataFrame.\n",
      "\n",
      "--- First 5 rows of the DataFrame ---\n",
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "-------------------------------------\n",
      "\n",
      "Number of duplicate rows based on 'MainBranch, Employment, RemoteWork': 64876\n",
      "-------------------------------------\n",
      "\n",
      "--- First few duplicate rows based on 'MainBranch, Employment, RemoteWork' (keeping all occurrences) ---\n",
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "-----------------------------------------------------------\n",
      "\n",
      "--- Analysis of identical values in duplicate rows for 'MainBranch, Employment, RemoteWork' ---\n",
      "\n",
      "Frequency of values in 'MainBranch' within duplicate rows:\n",
      "MainBranch\n",
      "I am a developer by profession                                                           50161\n",
      "I am not primarily a developer, but I write code sometimes as part of my work/studies     6468\n",
      "I am learning to code                                                                     3845\n",
      "I code primarily as a hobby                                                               3314\n",
      "I used to be a developer by profession, but no longer am                                  1482\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Frequency of values in 'Employment' within duplicate rows:\n",
      "Employment\n",
      "Employed, full-time                                                                                                                                                       39038\n",
      "Independent contractor, freelancer, or self-employed                                                                                                                       4844\n",
      "Student, full-time                                                                                                                                                         4709\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed                                                                                                   3557\n",
      "Not employed, but looking for work                                                                                                                                         2341\n",
      "                                                                                                                                                                          ...  \n",
      "Employed, full-time;Student, full-time;Student, part-time                                                                                                                     2\n",
      "Independent contractor, freelancer, or self-employed;Student, part-time;Retired                                                                                               2\n",
      "Not employed, but looking for work;Retired                                                                                                                                    2\n",
      "Not employed, and not looking for work;Employed, part-time                                                                                                                    2\n",
      "Employed, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time        2\n",
      "Name: count, Length: 72, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Frequency of values in 'RemoteWork' within duplicate rows:\n",
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    22974\n",
      "Remote                                  20779\n",
      "In-person                               10923\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "-----------------------------------------------------------\n",
      "\n",
      "--- Visualizing Distribution of Duplicates ---\n",
      "An unexpected error occurred while reading the CSV: name 'sns' is not defined\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "import pandas as pd # Ensure pandas is imported as pd\n",
    "import matplotlib.pyplot as plt # Import for plotting\n",
    "\n",
    "\n",
    "# Define the file_name, assuming it was successfully downloaded and saved in a previous step\n",
    "# Use the filename directly, as it should be in the current working directory of the environment.\n",
    "\n",
    "\n",
    "print(f\"Attempting to read data from: {file_name}\")\n",
    "\n",
    "try:\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\")\n",
    " \n",
    "\n",
    "    print(f\"Successfully loaded '{file_name}' into a DataFrame.\")\n",
    "    print(\"\\n--- First 5 rows of the DataFrame ---\")\n",
    "    print(df.head())\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # Define the subset of columns for duplicate check\n",
    "    columns_for_duplicate_check = ['MainBranch', 'Employment', 'RemoteWork']\n",
    "\n",
    "    # Count the number of duplicate rows based on the specified subset of columns\n",
    "    # df.duplicated(subset=columns_for_duplicate_check).sum() counts rows where the subset is duplicated\n",
    "    num_duplicate_rows_subset = df.duplicated(subset=columns_for_duplicate_check).sum()\n",
    "    print(f\"Number of duplicate rows based on '{', '.join(columns_for_duplicate_check)}': {num_duplicate_rows_subset}\")\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # Display the first few duplicate rows based on the subset\n",
    "    if num_duplicate_rows_subset > 0:\n",
    "        print(f\"--- First few duplicate rows based on '{', '.join(columns_for_duplicate_check)}' (keeping all occurrences) ---\")\n",
    "        # df.duplicated(subset=columns_for_duplicate_check, keep=False) marks all occurrences as True\n",
    "        duplicate_rows_subset = df[df.duplicated(subset=columns_for_duplicate_check, keep=False)]\n",
    "        print(duplicate_rows_subset.head())\n",
    "        print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "        # Analyze which columns frequently contain identical values within these duplicate rows\n",
    "        print(f\"--- Analysis of identical values in duplicate rows for '{', '.join(columns_for_duplicate_check)}' ---\")\n",
    "        for col in columns_for_duplicate_check:\n",
    "            if col in duplicate_rows_subset.columns:\n",
    "                print(f\"\\nFrequency of values in '{col}' within duplicate rows:\")\n",
    "                print(duplicate_rows_subset[col].value_counts())\n",
    "                print(\"-\" * 30)\n",
    "            else:\n",
    "                print(f\"Column '{col}' not found in the duplicate rows DataFrame.\")\n",
    "        print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "        # --- Create visualizations for distribution of duplicates ---\n",
    "        print(\"--- Visualizing Distribution of Duplicates ---\")\n",
    "\n",
    "        # Set a style for better aesthetics\n",
    "        sns.set_style(\"whitegrid\")\n",
    "\n",
    "        # Distribution by Country\n",
    "        if 'Country' in duplicate_rows_subset.columns:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            country_counts = duplicate_rows_subset['Country'].value_counts().nlargest(10) # Top 10 countries\n",
    "            sns.barplot(x=country_counts.index, y=country_counts.values, palette='viridis')\n",
    "            plt.title('Top 10 Countries with Duplicate Entries (based on MainBranch, Employment, RemoteWork)')\n",
    "            plt.xlabel('Country')\n",
    "            plt.ylabel('Number of Duplicate Entries')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Column 'Country' not found in the duplicate rows DataFrame for visualization.\")\n",
    "\n",
    "        # Distribution by Employment\n",
    "        if 'Employment' in duplicate_rows_subset.columns:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            employment_counts = duplicate_rows_subset['Employment'].value_counts()\n",
    "            sns.barplot(x=employment_counts.index, y=employment_counts.values, palette='magma')\n",
    "            plt.title('Distribution of Duplicate Entries by Employment Type')\n",
    "            plt.xlabel('Employment Type')\n",
    "            plt.ylabel('Number of Duplicate Entries')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Column 'Employment' not found in the duplicate rows DataFrame for visualization.\")\n",
    "\n",
    "        print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "    else:\n",
    "        print(f\"No duplicate rows found based on '{', '.join(columns_for_duplicate_check)}' to display or analyze.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_name}' was not found. Please ensure it exists in the current directory or was successfully downloaded/created.\")\n",
    "except pd.errors.EmptyDataError: # Specific error for empty files\n",
    "    print(f\"Error: The file '{file_name}' is empty or contains no data to parse. Please ensure the file has content.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while reading the CSV: {e}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Strategic Removal of Duplicates\n",
    "1. Decide which columns are critical for defining uniqueness in the dataset.\n",
    "2. Remove duplicates based on a subset of columns if complete row duplication is not a good criterion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read data from: survey_data.csv\n",
      "Successfully loaded 'survey_data.csv' into a DataFrame.\n",
      "\n",
      "--- First 5 rows of the DataFrame ---\n",
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "-------------------------------------\n",
      "\n",
      "Number of full duplicate rows in the dataset: 0\n",
      "No full duplicate rows found.\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "Deciding critical columns for uniqueness: MainBranch, Employment, RemoteWork, Country, EdLevel, Age\n",
      "Number of duplicate entries based on these critical columns before removal: 45386\n",
      "Duplicates removed based on 'MainBranch, Employment, RemoteWork, Country, EdLevel, Age'.\n",
      "New DataFrame shape after removing duplicates: (20051, 114)\n",
      "-------------------------------------\n",
      "\n",
      "Number of duplicate rows based on 'MainBranch, Employment, RemoteWork' (after main de-duplication): 19490\n",
      "-------------------------------------\n",
      "\n",
      "--- First few duplicate rows based on 'MainBranch, Employment, RemoteWork' (keeping all occurrences) ---\n",
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "-----------------------------------------------------------\n",
      "\n",
      "--- Analysis of identical values in duplicate rows for 'MainBranch, Employment, RemoteWork' ---\n",
      "\n",
      "Frequency of values in 'MainBranch' within duplicate rows:\n",
      "MainBranch\n",
      "I am a developer by profession                                                           11610\n",
      "I am not primarily a developer, but I write code sometimes as part of my work/studies     3445\n",
      "I am learning to code                                                                     2022\n",
      "I code primarily as a hobby                                                               1801\n",
      "I used to be a developer by profession, but no longer am                                  1005\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Frequency of values in 'Employment' within duplicate rows:\n",
      "Employment\n",
      "Employed, full-time                                                                                                                                                       6089\n",
      "Independent contractor, freelancer, or self-employed                                                                                                                      2248\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed                                                                                                  1590\n",
      "Student, full-time                                                                                                                                                        1407\n",
      "Not employed, but looking for work                                                                                                                                        1149\n",
      "                                                                                                                                                                          ... \n",
      "Not employed, but looking for work;Retired                                                                                                                                   2\n",
      "Independent contractor, freelancer, or self-employed;Student, part-time;Retired                                                                                              2\n",
      "Not employed, and not looking for work;Employed, part-time                                                                                                                   2\n",
      "Student, full-time;Not employed, but looking for work;Employed, part-time                                                                                                    2\n",
      "Employed, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time       2\n",
      "Name: count, Length: 72, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Frequency of values in 'RemoteWork' within duplicate rows:\n",
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    5709\n",
      "Remote                                  5490\n",
      "In-person                               3731\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "-----------------------------------------------------------\n",
      "\n",
      "--- Visualizing Distribution of Categories (after de-duplication) ---\n",
      "An unexpected error occurred while reading the CSV: name 'sns' is not defined\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Define the file_name, assuming it was successfully downloaded and saved in a previous step\n",
    "# Use the filename directly, as it should be in the current working directory of the environment.\n",
    "\n",
    "\n",
    "print(f\"Attempting to read data from: {file_name}\")\n",
    "\n",
    "try:\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\")\n",
    "\n",
    "    print(f\"Successfully loaded '{file_name}' into a DataFrame.\")\n",
    "    print(\"\\n--- First 5 rows of the DataFrame ---\")\n",
    "    print(df.head())\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # --- Duplicate Analysis (Full Row Duplicates) ---\n",
    "    num_full_duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"Number of full duplicate rows in the dataset: {num_full_duplicate_rows}\")\n",
    "    if num_full_duplicate_rows > 0:\n",
    "        print(\"--- First few full duplicate rows (keeping all occurrences) ---\")\n",
    "        print(df[df.duplicated(keep=False)].head())\n",
    "    else:\n",
    "        print(\"No full duplicate rows found.\")\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "\n",
    "    # --- Decide on Critical Columns for Uniqueness and Remove Duplicates ---\n",
    "    # For a survey dataset, a unique respondent is often identified by a combination of key demographic or identifier columns.\n",
    "    # Assuming no explicit unique ID like 'ResponseId', we'll use a combination of demographic and core response columns.\n",
    "    potential_critical_uniqueness_columns = ['MainBranch', 'Employment', 'RemoteWork', 'Country', 'EdLevel', 'Age']\n",
    "\n",
    "    # Filter to only include columns that actually exist in the DataFrame\n",
    "    critical_uniqueness_columns = [col for col in potential_critical_uniqueness_columns if col in df.columns]\n",
    "\n",
    "    if not critical_uniqueness_columns:\n",
    "        print(\"Warning: No critical uniqueness columns found in the dataset. Cannot remove duplicates based on subset.\")\n",
    "    else:\n",
    "        print(f\"\\nDeciding critical columns for uniqueness: {', '.join(critical_uniqueness_columns)}\")\n",
    "        # Count duplicates based on these critical columns before removal\n",
    "        num_duplicates_before_removal = df.duplicated(subset=critical_uniqueness_columns).sum()\n",
    "        print(f\"Number of duplicate entries based on these critical columns before removal: {num_duplicates_before_removal}\")\n",
    "\n",
    "        # Remove duplicates based on the identified critical columns\n",
    "        # inplace=True modifies the DataFrame directly\n",
    "        df.drop_duplicates(subset=critical_uniqueness_columns, inplace=True)\n",
    "        print(f\"Duplicates removed based on '{', '.join(critical_uniqueness_columns)}'.\")\n",
    "        print(f\"New DataFrame shape after removing duplicates: {df.shape}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "\n",
    "\n",
    "    # --- Identify and Analyze Duplicates based on Specific Subset (MainBranch, Employment, RemoteWork) ---\n",
    "    # This analysis is performed on the potentially de-duplicated 'df' now\n",
    "    columns_for_analysis_subset = ['MainBranch', 'Employment', 'RemoteWork']\n",
    "    \n",
    "    # Check if these columns exist in the DataFrame before proceeding\n",
    "    if all(col in df.columns for col in columns_for_analysis_subset):\n",
    "        num_duplicate_rows_analysis_subset = df.duplicated(subset=columns_for_analysis_subset).sum()\n",
    "        print(f\"Number of duplicate rows based on '{', '.join(columns_for_analysis_subset)}' (after main de-duplication): {num_duplicate_rows_analysis_subset}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "\n",
    "        if num_duplicate_rows_analysis_subset > 0:\n",
    "            print(f\"--- First few duplicate rows based on '{', '.join(columns_for_analysis_subset)}' (keeping all occurrences) ---\")\n",
    "            duplicate_rows_analysis_subset = df[df.duplicated(subset=columns_for_analysis_subset, keep=False)]\n",
    "            print(duplicate_rows_analysis_subset.head())\n",
    "            print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "            print(f\"--- Analysis of identical values in duplicate rows for '{', '.join(columns_for_analysis_subset)}' ---\")\n",
    "            for col in columns_for_analysis_subset:\n",
    "                print(f\"\\nFrequency of values in '{col}' within duplicate rows:\")\n",
    "                print(duplicate_rows_analysis_subset[col].value_counts())\n",
    "                print(\"-\" * 30)\n",
    "            print(\"-----------------------------------------------------------\\n\")\n",
    "        else:\n",
    "            print(f\"No duplicate rows found based on '{', '.join(columns_for_analysis_subset)}' after main de-duplication to display or analyze.\")\n",
    "    else:\n",
    "        print(f\"One or more columns ({', '.join(columns_for_analysis_subset)}) not found in the DataFrame for analysis.\")\n",
    "\n",
    "\n",
    "    # --- Create visualizations to show the distribution of duplicates across different categories ---\n",
    "    # These visualizations will now reflect the de-duplicated DataFrame 'df'\n",
    "    print(\"--- Visualizing Distribution of Categories (after de-duplication) ---\")\n",
    "\n",
    "    # Set a style for better aesthetics\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Distribution by Country\n",
    "    if 'Country' in df.columns: # Check if 'Country' column exists in the (potentially de-duplicated) df\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        country_counts = df['Country'].value_counts().nlargest(10) # Top 10 countries\n",
    "        sns.barplot(x=country_counts.index, y=country_counts.values, palette='viridis')\n",
    "        plt.title('Top 10 Countries Distribution (after de-duplication)')\n",
    "        plt.xlabel('Country')\n",
    "        plt.ylabel('Number of Entries')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Column 'Country' not found in the DataFrame for visualization.\")\n",
    "\n",
    "    # Distribution by Employment\n",
    "    if 'Employment' in df.columns: # Check if 'Employment' column exists in the (potentially de-duplicated) df\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        employment_counts = df['Employment'].value_counts()\n",
    "        sns.barplot(x=employment_counts.index, y=employment_counts.values, palette='magma')\n",
    "        plt.title('Employment Type Distribution (after de-duplication)')\n",
    "        plt.xlabel('Employment Type')\n",
    "        plt.ylabel('Number of Entries')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Column 'Employment' not found in the DataFrame for visualization.\")\n",
    "\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_name}' was not found. Please ensure it exists in the current directory or was successfully downloaded/created.\")\n",
    "except pd.errors.EmptyDataError: # Specific error for empty files\n",
    "    print(f\"Error: The file '{file_name}' is empty or contains no data to parse. Please ensure the file has content.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while reading the CSV: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify and Document Duplicate Removal Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Documentation\n",
    "1. Document the process of identifying and removing duplicates.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your explanation here\n",
    "Defining Duplication: Deciding what constitutes a \"duplicate.\" This can be an exact match across all columns or a match based on a specific subset of critical columns (e.g., ID, name, email, or a combination of key attributes that should uniquely identify an entry).\n",
    "\n",
    "Detection: Using tools or functions (like pandas' .duplicated() method) to flag rows that meet the defined duplication criteria.\n",
    "\n",
    "Analysis (Optional but Recommended): Examining the flagged duplicates to understand their structure, frequency, and the columns often involved. This helps confirm if the duplication definition is appropriate.\n",
    "\n",
    "Removal: Deleting the identified duplicate rows, typically keeping only the first or last occurrence, or a specific preferred record, to ensure each unique entry is represented only once (e.g., pandas' .drop_duplicates() method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explain the reasoning behind selecting specific columns for identifying and removing duplicates.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your explanation here\n",
    "Identifying and removing duplicates based on specific columns rather than the entire row is crucial when complete row duplication isn't the sole indicator of a redundant entry. This approach ensures that you're only removing records that are identical in the attributes critical for defining a unique entity.\n",
    "\n",
    "For example, in a survey dataset, two respondents might accidentally have identical values in demographic fields like Country and Employment. If ResponseId is also a column and each ResponseId is truly unique, then matching Country and Employment alone doesn't mean the entire row is a duplicate. However, if the goal is to analyze unique demographic profiles, then you'd define uniqueness by these specific columns, even if other parts of the row (like a timestamp) differ. This method allows for a more nuanced and context-aware data cleaning, preventing the accidental removal of genuinely distinct entries that might coincidentally share values in some non-critical fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and Next Steps\n",
    "**In this lab, you focused on identifying and analyzing duplicate rows within the dataset.**\n",
    "\n",
    "- You employed various techniques to explore the nature of duplicates and applied strategic methods for their removal.\n",
    "- For additional analysis, consider investigating the impact of duplicates on specific analyses and how their removal affects the results.\n",
    "- This version of the lab is more focused on duplicate analysis and handling, providing a structured approach to deal with duplicates in a dataset effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2024-11- 05|1.3|Madhusudhan Moole|Updated lab|\n",
    "|2024-10-28|1.2|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-24|1.1|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-23|1.0|Raghul Ramesh|Created lab|\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "fa3493caccf457f2b33a3a72ca6bf5789c2ce4157ea6e40534b09cc8380e8ae5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
