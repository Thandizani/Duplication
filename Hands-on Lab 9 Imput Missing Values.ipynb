{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Impute Missing Values**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will practice essential data wrangling techniques using the Stack Overflow survey dataset. The primary focus is on handling missing data and ensuring data quality. You will:\n",
    "\n",
    "- **Load the Data:** Import the dataset into a DataFrame using the pandas library.\n",
    "\n",
    "- **Clean the Data:** Identify and remove duplicate entries to maintain data integrity.\n",
    "\n",
    "- **Handle Missing Values:** Detect missing values, impute them with appropriate strategies, and verify the imputation to create a complete and reliable dataset for analysis.\n",
    "\n",
    "This lab equips you with the skills to effectively preprocess and clean real-world datasets, a crucial step in any data analysis project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Identify missing values in the dataset.\n",
    "\n",
    "-   Apply techniques to impute missing values in the dataset.\n",
    "  \n",
    "-   Use suitable techniques to normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install needed library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.2 pandas-2.3.1 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset Into a Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Read Data**\n",
    "<p>\n",
    "The functions below will download the dataset into your browser:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to ensure it loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Finding and Removing Duplicates\n",
    "##### Task 1: Identify duplicate rows in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of full duplicate rows in the dataset: 0\n",
      "-------------------------------------\n",
      "\n",
      "No full duplicate rows found to display or remove.\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# --- Duplicate Analysis (Full Row Duplicates) ---\n",
    "    # Count the number of duplicate rows\n",
    "num_full_duplicate_rows = df.duplicated().sum()\n",
    "print(f\"Number of full duplicate rows in the dataset: {num_full_duplicate_rows}\")\n",
    "print(\"-------------------------------------\\n\")\n",
    "\n",
    "# Display the first few duplicate rows\n",
    "if num_full_duplicate_rows > 0:\n",
    "    print(\"--- First few full duplicate rows (keeping all occurrences) ---\")\n",
    "    # df.duplicated(keep=False) marks all occurrences of a duplicate row as True\n",
    "    # This allows us to see both the original and its duplicates, providing context.\n",
    "    duplicate_rows = df[df.duplicated(keep=False)]\n",
    "    print(duplicate_rows.head())\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "else:\n",
    "    print(\"No full duplicate rows found to display or remove.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: Remove the duplicate rows from the dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Finding Missing Values\n",
    "##### Task 3: Find the missing values for all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Identifying Missing Values Across All Columns ---\n",
      "Columns with Missing Values:\n",
      "                            Missing Count  Missing Percentage\n",
      "AINextMuch less integrated          64289           98.245641\n",
      "AINextLess integrated               63082           96.401119\n",
      "AINextNo change                     52939           80.900714\n",
      "AINextMuch more integrated          51999           79.464217\n",
      "EmbeddedAdmired                     48704           74.428840\n",
      "...                                   ...                 ...\n",
      "YearsCode                            5568            8.508948\n",
      "NEWSOSites                           5151            7.871693\n",
      "LearnCode                            4949            7.563000\n",
      "EdLevel                              4653            7.110656\n",
      "AISelect                             4530            6.922689\n",
      "\n",
      "[109 rows x 2 columns]\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# --- Identify Missing Values ---\n",
    "print(\"--- Identifying Missing Values Across All Columns ---\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "# Filter to show only columns with missing values and sort by percentage\n",
    "missing_info = missing_info[missing_info['Missing Count'] > 0].sort_values(\n",
    "    by='Missing Percentage', ascending=False\n",
    ")\n",
    "\n",
    "if not missing_info.empty:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    print(missing_info)\n",
    "else:\n",
    "    print(\"No missing values found in any column.\")\n",
    "print(\"---------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4: Find out how many rows are missing in the column RemoteWork.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the 'RemoteWork' column: 10631\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# --- Count Missing Values for a Specific Column (e.g., RemoteWork) ---\n",
    "specific_column_count_missing_remotework = 'RemoteWork'\n",
    "if specific_column_count_missing_remotework in df.columns:\n",
    "    missing_count_specific_column_remotework = df[specific_column_count_missing_remotework].isnull().sum()\n",
    "    print(f\"Number of missing values in the '{specific_column_count_missing_remotework}' column: {missing_count_specific_column_remotework}\")\n",
    "    print(\"---------------------------------------------------\\n\")\n",
    "else:\n",
    "    print(f\"Column '{specific_column_count_missing_remotework}' not found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Imputing Missing Values\n",
    "##### Task 5: Find the value counts for the column RemoteWork.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Value Counts for 'RemoteWork' Column ---\n",
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    23015\n",
      "Remote                                  20831\n",
      "In-person                               10960\n",
      "NaN                                     10631\n",
      "Name: count, dtype: int64\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# --- Find Value Counts for 'RemoteWork' Column ---\n",
    "column_for_value_counts = 'RemoteWork'\n",
    "if column_for_value_counts in df.columns:\n",
    "    print(f\"--- Value Counts for '{column_for_value_counts}' Column ---\")\n",
    "    print(df[column_for_value_counts].value_counts(dropna=False)) # dropna=False includes NaN counts\n",
    "    print(\"---------------------------------------------------\\n\")\n",
    "else:\n",
    "    print(f\"Column '{column_for_value_counts}' not found in the DataFrame. Cannot display value counts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 6: Identify the most frequent (majority) value in the RemoteWork column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent value in the 'RemoteWork' column: 'Hybrid (some remote, some in-person)'\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# --- Identify Most Frequent Value in 'RemoteWork' Column ---\n",
    "column_for_mode_remotework = 'RemoteWork'\n",
    "if column_for_mode_remotework in df.columns:\n",
    "    # Calculate the mode (most frequent value)\n",
    "    # .mode()[0] is used because mode() can return multiple values if there's a tie\n",
    "    most_frequent_value_remotework = df[column_for_mode_remotework].mode()[0]\n",
    "    print(f\"Most frequent value in the '{column_for_mode_remotework}' column: '{most_frequent_value_remotework}'\")\n",
    "    print(\"---------------------------------------------------\\n\")\n",
    "else:\n",
    "    print(f\"Column '{column_for_mode_remotework}' not found in the DataFrame. Cannot identify most frequent value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 7: Impute (replace) all the empty rows in the column RemoteWork with the majority value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Imputing Missing Values in 'RemoteWork' ---\n",
      "Most frequent value (mode) for 'RemoteWork': 'Hybrid (some remote, some in-person)'\n",
      "Missing values in 'RemoteWork' after imputation: 0\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300/2794842252.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column_to_impute_remotework].fillna(mode_value_remotework_impute, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# --- Impute Missing Values in 'RemoteWork' with Mode ---\n",
    "column_to_impute_remotework = 'RemoteWork'\n",
    "if column_to_impute_remotework in df.columns:\n",
    "    if df[column_to_impute_remotework].isnull().sum() > 0:\n",
    "        print(f\"--- Imputing Missing Values in '{column_to_impute_remotework}' ---\")\n",
    "        mode_value_remotework_impute = df[column_to_impute_remotework].mode()[0]\n",
    "        print(f\"Most frequent value (mode) for '{column_to_impute_remotework}': '{mode_value_remotework_impute}'\")\n",
    "        df[column_to_impute_remotework].fillna(mode_value_remotework_impute, inplace=True)\n",
    "        print(f\"Missing values in '{column_to_impute_remotework}' after imputation: {df[column_to_impute_remotework].isnull().sum()}\")\n",
    "        print(\"---------------------------------------------------\\n\")\n",
    "    else:\n",
    "        print(f\"No missing values found in '{column_to_impute_remotework}'. No imputation performed.\")\n",
    "else:\n",
    "    print(f\"Column '{column_to_impute_remotework}' not found in the DataFrame. Cannot perform imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 8: Check for any compensation-related columns and describe their distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Compensation Analysis using 'ConvertedCompYearly' ---\n",
      "Initial missing values in 'ConvertedCompYearly': 42002\n",
      "Total missing values in 'ConvertedCompYearly' after numeric conversion: 42002\n",
      "Imputing missing values in 'ConvertedCompYearly' with median: 65000.0\n",
      "Missing values in 'ConvertedCompYearly' after imputation: 0\n",
      "\n",
      "Descriptive Statistics for Annual Compensation (after imputation):\n",
      "count    6.543700e+04\n",
      "mean     7.257636e+04\n",
      "std      1.122207e+05\n",
      "min      1.000000e+00\n",
      "25%      6.500000e+04\n",
      "50%      6.500000e+04\n",
      "75%      6.500000e+04\n",
      "max      1.625660e+07\n",
      "Name: ConvertedCompYearly, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300/3271101780.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[compensation_column].fillna(median_comp, inplace=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(compensation_data[compensation_column]\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Visualize the distribution\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     40\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(compensation_data[compensation_column], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Annual Compensation (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompensation_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) (after imputation)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# --- Compensation Analysis using 'ConvertedCompYearly' ---\n",
    "compensation_column = 'ConvertedCompYearly'\n",
    "if compensation_column in df.columns:\n",
    "    print(f\"--- Compensation Analysis using '{compensation_column}' ---\")\n",
    "\n",
    "    # 1. Identify initial missing values\n",
    "    initial_missing_comp = df[compensation_column].isnull().sum()\n",
    "    print(f\"Initial missing values in '{compensation_column}': {initial_missing_comp}\")\n",
    "\n",
    "    # Convert the column to numeric, coercing errors to NaN\n",
    "    df[compensation_column] = pd.to_numeric(df[compensation_column], errors='coerce')\n",
    "\n",
    "    # Identify missing values after conversion (if any non-numeric values were coerced)\n",
    "    missing_after_coerce = df[compensation_column].isnull().sum()\n",
    "    if missing_after_coerce > initial_missing_comp:\n",
    "        print(f\"Additional NaNs introduced after converting to numeric: {missing_after_coerce - initial_missing_comp}\")\n",
    "    print(f\"Total missing values in '{compensation_column}' after numeric conversion: {missing_after_coerce}\")\n",
    "\n",
    "    # 2. Handle missing values (Imputation with Median for numerical data)\n",
    "    if missing_after_coerce > 0:\n",
    "        median_comp = df[compensation_column].median()\n",
    "        print(f\"Imputing missing values in '{compensation_column}' with median: {median_comp}\")\n",
    "        df[compensation_column].fillna(median_comp, inplace=True)\n",
    "        print(f\"Missing values in '{compensation_column}' after imputation: {df[compensation_column].isnull().sum()}\")\n",
    "    else:\n",
    "        print(f\"No missing values to impute in '{compensation_column}' after numeric conversion.\")\n",
    "\n",
    "    # Now, proceed with analysis on the imputed column\n",
    "    # Ensure compensation_data refers to the df after imputation\n",
    "    compensation_data = df # Use the DataFrame after imputation\n",
    "\n",
    "    if not compensation_data.empty: # This check is now less critical if NaNs are filled\n",
    "        # Display descriptive statistics\n",
    "        print(\"\\nDescriptive Statistics for Annual Compensation (after imputation):\")\n",
    "        print(compensation_data[compensation_column].describe())\n",
    "\n",
    "        # Visualize the distribution\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(compensation_data[compensation_column], bins=50, kde=True)\n",
    "        plt.title(f'Distribution of Annual Compensation ({compensation_column}) (after imputation)')\n",
    "        plt.xlabel('Annual Compensation (USD)')\n",
    "        plt.ylabel('Number of Respondents')\n",
    "        plt.ticklabel_format(style='plain', axis='x') # Prevent scientific notation on x-axis\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Optional: Box plot for outliers\n",
    "        plt.figure(figsize=(12, 2))\n",
    "        sns.boxplot(x=compensation_data[compensation_column])\n",
    "        plt.title(f'Box Plot of Annual Compensation ({compensation_column}) (after imputation)')\n",
    "        plt.xlabel('Annual Compensation (USD)')\n",
    "        plt.ticklabel_format(style='plain', axis='x')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"DataFrame is empty after processing '{compensation_column}'.\")\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "else:\n",
    "    print(f\"Column '{compensation_column}' not found in the DataFrame. Cannot perform compensation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this lab, you focused on imputing missing values in the dataset.**\n",
    "\n",
    "- Use the <code>pandas.read_csv()</code> function to load a dataset from a CSV file into a DataFrame.\n",
    "\n",
    "- Download the dataset if it's not available online and specify the correct file path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2024-11-05|1.3|Madhusudhan Moole|Updated lab|\n",
    "|2024-10-29|1.2|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-27|1.1|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-26|1.0|Raghul Ramesh|Created lab|\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "70ab641719bca2be0bdcb38f6a8b5de7851b6e9c28d41b9407096c62e74916a6"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
